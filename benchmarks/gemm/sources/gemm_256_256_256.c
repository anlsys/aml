#include <stdlib.h>
#include <inttypes.h>
#include <math.h>
#include "immintrin.h"
#define __assume_aligned(lvalueptr, align) lvalueptr = __builtin_assume_aligned (lvalueptr, align)
static void gemm_inn_64_48_128(const double * __restrict__ a, const __m512d * __restrict__ b, __m512d * __restrict__ c){
  __assume_aligned(a, 64);
  int32_t i;
  int32_t j;
  int32_t k;
  __m512d tmp_0_0;
  __m512d tmp_0_1;
  __m512d tmp_0_2;
  __m512d tmp_0_3;
  __m512d tmp_0_4;
  __m512d tmp_0_5;
  __m512d tmp_1_0;
  __m512d tmp_1_1;
  __m512d tmp_1_2;
  __m512d tmp_1_3;
  __m512d tmp_1_4;
  __m512d tmp_1_5;
  __m512d tmp_2_0;
  __m512d tmp_2_1;
  __m512d tmp_2_2;
  __m512d tmp_2_3;
  __m512d tmp_2_4;
  __m512d tmp_2_5;
  __m512d tmp_3_0;
  __m512d tmp_3_1;
  __m512d tmp_3_2;
  __m512d tmp_3_3;
  __m512d tmp_3_4;
  __m512d tmp_3_5;
  __m512d tmpa_0;
  __m512d tmpa_1;
  __m512d tmpa_2;
  __m512d tmpa_3;
  __m512d tmpa_4;
  __m512d tmpa_5;
  __m512d tmpb_0;
  __m512d tmpb_1;
  __m512d tmpb_2;
  __m512d tmpb_3;
  for (j = 0; j <= 47; j += 6) {
    for (i = 0; i <= 7; i += 4) {
      tmp_0_0 = c[i + 0 + (32) * (j + 0)];
      tmp_1_0 = c[i + 1 + (32) * (j + 0)];
      tmp_2_0 = c[i + 2 + (32) * (j + 0)];
      tmp_3_0 = c[i + 3 + (32) * (j + 0)];
      tmp_0_1 = c[i + 0 + (32) * (j + 1)];
      tmp_1_1 = c[i + 1 + (32) * (j + 1)];
      tmp_2_1 = c[i + 2 + (32) * (j + 1)];
      tmp_3_1 = c[i + 3 + (32) * (j + 1)];
      tmp_0_2 = c[i + 0 + (32) * (j + 2)];
      tmp_1_2 = c[i + 1 + (32) * (j + 2)];
      tmp_2_2 = c[i + 2 + (32) * (j + 2)];
      tmp_3_2 = c[i + 3 + (32) * (j + 2)];
      tmp_0_3 = c[i + 0 + (32) * (j + 3)];
      tmp_1_3 = c[i + 1 + (32) * (j + 3)];
      tmp_2_3 = c[i + 2 + (32) * (j + 3)];
      tmp_3_3 = c[i + 3 + (32) * (j + 3)];
      tmp_0_4 = c[i + 0 + (32) * (j + 4)];
      tmp_1_4 = c[i + 1 + (32) * (j + 4)];
      tmp_2_4 = c[i + 2 + (32) * (j + 4)];
      tmp_3_4 = c[i + 3 + (32) * (j + 4)];
      tmp_0_5 = c[i + 0 + (32) * (j + 5)];
      tmp_1_5 = c[i + 1 + (32) * (j + 5)];
      tmp_2_5 = c[i + 2 + (32) * (j + 5)];
      tmp_3_5 = c[i + 3 + (32) * (j + 5)];
      for (k = 0; k <= 127; k += 2) {
        tmpb_0 = b[i + 0 + (32) * (k + 0)];
        tmpa_0 = _mm512_set1_pd( a[k + 0 + (256) * (j + 0)] );
        tmp_0_0 = _mm512_fmadd_pd( tmpa_0, tmpb_0, tmp_0_0 );
        tmpa_1 = _mm512_set1_pd( a[k + 0 + (256) * (j + 1)] );
        tmp_0_1 = _mm512_fmadd_pd( tmpa_1, tmpb_0, tmp_0_1 );
        tmpa_2 = _mm512_set1_pd( a[k + 0 + (256) * (j + 2)] );
        tmp_0_2 = _mm512_fmadd_pd( tmpa_2, tmpb_0, tmp_0_2 );
        tmpa_3 = _mm512_set1_pd( a[k + 0 + (256) * (j + 3)] );
        tmp_0_3 = _mm512_fmadd_pd( tmpa_3, tmpb_0, tmp_0_3 );
        tmpa_4 = _mm512_set1_pd( a[k + 0 + (256) * (j + 4)] );
        tmp_0_4 = _mm512_fmadd_pd( tmpa_4, tmpb_0, tmp_0_4 );
        tmpa_5 = _mm512_set1_pd( a[k + 0 + (256) * (j + 5)] );
        tmp_0_5 = _mm512_fmadd_pd( tmpa_5, tmpb_0, tmp_0_5 );
        tmpb_1 = b[i + 1 + (32) * (k + 0)];
        tmp_1_0 = _mm512_fmadd_pd( tmpa_0, tmpb_1, tmp_1_0 );
        tmp_1_1 = _mm512_fmadd_pd( tmpa_1, tmpb_1, tmp_1_1 );
        tmp_1_2 = _mm512_fmadd_pd( tmpa_2, tmpb_1, tmp_1_2 );
        tmp_1_3 = _mm512_fmadd_pd( tmpa_3, tmpb_1, tmp_1_3 );
        tmp_1_4 = _mm512_fmadd_pd( tmpa_4, tmpb_1, tmp_1_4 );
        tmp_1_5 = _mm512_fmadd_pd( tmpa_5, tmpb_1, tmp_1_5 );
        tmpb_2 = b[i + 2 + (32) * (k + 0)];
        tmp_2_0 = _mm512_fmadd_pd( tmpa_0, tmpb_2, tmp_2_0 );
        tmp_2_1 = _mm512_fmadd_pd( tmpa_1, tmpb_2, tmp_2_1 );
        tmp_2_2 = _mm512_fmadd_pd( tmpa_2, tmpb_2, tmp_2_2 );
        tmp_2_3 = _mm512_fmadd_pd( tmpa_3, tmpb_2, tmp_2_3 );
        tmp_2_4 = _mm512_fmadd_pd( tmpa_4, tmpb_2, tmp_2_4 );
        tmp_2_5 = _mm512_fmadd_pd( tmpa_5, tmpb_2, tmp_2_5 );
        tmpb_3 = b[i + 3 + (32) * (k + 0)];
        tmp_3_0 = _mm512_fmadd_pd( tmpa_0, tmpb_3, tmp_3_0 );
        tmp_3_1 = _mm512_fmadd_pd( tmpa_1, tmpb_3, tmp_3_1 );
        tmp_3_2 = _mm512_fmadd_pd( tmpa_2, tmpb_3, tmp_3_2 );
        tmp_3_3 = _mm512_fmadd_pd( tmpa_3, tmpb_3, tmp_3_3 );
        tmp_3_4 = _mm512_fmadd_pd( tmpa_4, tmpb_3, tmp_3_4 );
        tmp_3_5 = _mm512_fmadd_pd( tmpa_5, tmpb_3, tmp_3_5 );
        tmpb_0 = b[i + 0 + (32) * (k + 1)];
        tmpa_0 = _mm512_set1_pd( a[k + 1 + (256) * (j + 0)] );
        tmp_0_0 = _mm512_fmadd_pd( tmpa_0, tmpb_0, tmp_0_0 );
        tmpa_1 = _mm512_set1_pd( a[k + 1 + (256) * (j + 1)] );
        tmp_0_1 = _mm512_fmadd_pd( tmpa_1, tmpb_0, tmp_0_1 );
        tmpa_2 = _mm512_set1_pd( a[k + 1 + (256) * (j + 2)] );
        tmp_0_2 = _mm512_fmadd_pd( tmpa_2, tmpb_0, tmp_0_2 );
        tmpa_3 = _mm512_set1_pd( a[k + 1 + (256) * (j + 3)] );
        tmp_0_3 = _mm512_fmadd_pd( tmpa_3, tmpb_0, tmp_0_3 );
        tmpa_4 = _mm512_set1_pd( a[k + 1 + (256) * (j + 4)] );
        tmp_0_4 = _mm512_fmadd_pd( tmpa_4, tmpb_0, tmp_0_4 );
        tmpa_5 = _mm512_set1_pd( a[k + 1 + (256) * (j + 5)] );
        tmp_0_5 = _mm512_fmadd_pd( tmpa_5, tmpb_0, tmp_0_5 );
        tmpb_1 = b[i + 1 + (32) * (k + 1)];
        tmp_1_0 = _mm512_fmadd_pd( tmpa_0, tmpb_1, tmp_1_0 );
        tmp_1_1 = _mm512_fmadd_pd( tmpa_1, tmpb_1, tmp_1_1 );
        tmp_1_2 = _mm512_fmadd_pd( tmpa_2, tmpb_1, tmp_1_2 );
        tmp_1_3 = _mm512_fmadd_pd( tmpa_3, tmpb_1, tmp_1_3 );
        tmp_1_4 = _mm512_fmadd_pd( tmpa_4, tmpb_1, tmp_1_4 );
        tmp_1_5 = _mm512_fmadd_pd( tmpa_5, tmpb_1, tmp_1_5 );
        tmpb_2 = b[i + 2 + (32) * (k + 1)];
        tmp_2_0 = _mm512_fmadd_pd( tmpa_0, tmpb_2, tmp_2_0 );
        tmp_2_1 = _mm512_fmadd_pd( tmpa_1, tmpb_2, tmp_2_1 );
        tmp_2_2 = _mm512_fmadd_pd( tmpa_2, tmpb_2, tmp_2_2 );
        tmp_2_3 = _mm512_fmadd_pd( tmpa_3, tmpb_2, tmp_2_3 );
        tmp_2_4 = _mm512_fmadd_pd( tmpa_4, tmpb_2, tmp_2_4 );
        tmp_2_5 = _mm512_fmadd_pd( tmpa_5, tmpb_2, tmp_2_5 );
        tmpb_3 = b[i + 3 + (32) * (k + 1)];
        tmp_3_0 = _mm512_fmadd_pd( tmpa_0, tmpb_3, tmp_3_0 );
        tmp_3_1 = _mm512_fmadd_pd( tmpa_1, tmpb_3, tmp_3_1 );
        tmp_3_2 = _mm512_fmadd_pd( tmpa_2, tmpb_3, tmp_3_2 );
        tmp_3_3 = _mm512_fmadd_pd( tmpa_3, tmpb_3, tmp_3_3 );
        tmp_3_4 = _mm512_fmadd_pd( tmpa_4, tmpb_3, tmp_3_4 );
        tmp_3_5 = _mm512_fmadd_pd( tmpa_5, tmpb_3, tmp_3_5 );
      }
      c[i + 0 + (32) * (j + 0)] = tmp_0_0;
      c[i + 1 + (32) * (j + 0)] = tmp_1_0;
      c[i + 2 + (32) * (j + 0)] = tmp_2_0;
      c[i + 3 + (32) * (j + 0)] = tmp_3_0;
      c[i + 0 + (32) * (j + 1)] = tmp_0_1;
      c[i + 1 + (32) * (j + 1)] = tmp_1_1;
      c[i + 2 + (32) * (j + 1)] = tmp_2_1;
      c[i + 3 + (32) * (j + 1)] = tmp_3_1;
      c[i + 0 + (32) * (j + 2)] = tmp_0_2;
      c[i + 1 + (32) * (j + 2)] = tmp_1_2;
      c[i + 2 + (32) * (j + 2)] = tmp_2_2;
      c[i + 3 + (32) * (j + 2)] = tmp_3_2;
      c[i + 0 + (32) * (j + 3)] = tmp_0_3;
      c[i + 1 + (32) * (j + 3)] = tmp_1_3;
      c[i + 2 + (32) * (j + 3)] = tmp_2_3;
      c[i + 3 + (32) * (j + 3)] = tmp_3_3;
      c[i + 0 + (32) * (j + 4)] = tmp_0_4;
      c[i + 1 + (32) * (j + 4)] = tmp_1_4;
      c[i + 2 + (32) * (j + 4)] = tmp_2_4;
      c[i + 3 + (32) * (j + 4)] = tmp_3_4;
      c[i + 0 + (32) * (j + 5)] = tmp_0_5;
      c[i + 1 + (32) * (j + 5)] = tmp_1_5;
      c[i + 2 + (32) * (j + 5)] = tmp_2_5;
      c[i + 3 + (32) * (j + 5)] = tmp_3_5;
    }
  }
}
static void gemm_inn_64_16_128(const double * __restrict__ a, const __m512d * __restrict__ b, __m512d * __restrict__ c){
  __assume_aligned(a, 64);
  int32_t i;
  int32_t j;
  int32_t k;
  __m512d tmp_0_0;
  __m512d tmp_0_1;
  __m512d tmp_0_2;
  __m512d tmp_0_3;
  __m512d tmp_1_0;
  __m512d tmp_1_1;
  __m512d tmp_1_2;
  __m512d tmp_1_3;
  __m512d tmp_2_0;
  __m512d tmp_2_1;
  __m512d tmp_2_2;
  __m512d tmp_2_3;
  __m512d tmp_3_0;
  __m512d tmp_3_1;
  __m512d tmp_3_2;
  __m512d tmp_3_3;
  __m512d tmpa_0;
  __m512d tmpa_1;
  __m512d tmpa_2;
  __m512d tmpa_3;
  __m512d tmpb_0;
  __m512d tmpb_1;
  __m512d tmpb_2;
  __m512d tmpb_3;
  for (j = 0; j <= 15; j += 4) {
    for (i = 0; i <= 7; i += 4) {
      tmp_0_0 = c[i + 0 + (32) * (j + 0)];
      tmp_1_0 = c[i + 1 + (32) * (j + 0)];
      tmp_2_0 = c[i + 2 + (32) * (j + 0)];
      tmp_3_0 = c[i + 3 + (32) * (j + 0)];
      tmp_0_1 = c[i + 0 + (32) * (j + 1)];
      tmp_1_1 = c[i + 1 + (32) * (j + 1)];
      tmp_2_1 = c[i + 2 + (32) * (j + 1)];
      tmp_3_1 = c[i + 3 + (32) * (j + 1)];
      tmp_0_2 = c[i + 0 + (32) * (j + 2)];
      tmp_1_2 = c[i + 1 + (32) * (j + 2)];
      tmp_2_2 = c[i + 2 + (32) * (j + 2)];
      tmp_3_2 = c[i + 3 + (32) * (j + 2)];
      tmp_0_3 = c[i + 0 + (32) * (j + 3)];
      tmp_1_3 = c[i + 1 + (32) * (j + 3)];
      tmp_2_3 = c[i + 2 + (32) * (j + 3)];
      tmp_3_3 = c[i + 3 + (32) * (j + 3)];
      for (k = 0; k <= 127; k += 2) {
        tmpb_0 = b[i + 0 + (32) * (k + 0)];
        tmpa_0 = _mm512_set1_pd( a[k + 0 + (256) * (j + 0)] );
        tmp_0_0 = _mm512_fmadd_pd( tmpa_0, tmpb_0, tmp_0_0 );
        tmpa_1 = _mm512_set1_pd( a[k + 0 + (256) * (j + 1)] );
        tmp_0_1 = _mm512_fmadd_pd( tmpa_1, tmpb_0, tmp_0_1 );
        tmpa_2 = _mm512_set1_pd( a[k + 0 + (256) * (j + 2)] );
        tmp_0_2 = _mm512_fmadd_pd( tmpa_2, tmpb_0, tmp_0_2 );
        tmpa_3 = _mm512_set1_pd( a[k + 0 + (256) * (j + 3)] );
        tmp_0_3 = _mm512_fmadd_pd( tmpa_3, tmpb_0, tmp_0_3 );
        tmpb_1 = b[i + 1 + (32) * (k + 0)];
        tmp_1_0 = _mm512_fmadd_pd( tmpa_0, tmpb_1, tmp_1_0 );
        tmp_1_1 = _mm512_fmadd_pd( tmpa_1, tmpb_1, tmp_1_1 );
        tmp_1_2 = _mm512_fmadd_pd( tmpa_2, tmpb_1, tmp_1_2 );
        tmp_1_3 = _mm512_fmadd_pd( tmpa_3, tmpb_1, tmp_1_3 );
        tmpb_2 = b[i + 2 + (32) * (k + 0)];
        tmp_2_0 = _mm512_fmadd_pd( tmpa_0, tmpb_2, tmp_2_0 );
        tmp_2_1 = _mm512_fmadd_pd( tmpa_1, tmpb_2, tmp_2_1 );
        tmp_2_2 = _mm512_fmadd_pd( tmpa_2, tmpb_2, tmp_2_2 );
        tmp_2_3 = _mm512_fmadd_pd( tmpa_3, tmpb_2, tmp_2_3 );
        tmpb_3 = b[i + 3 + (32) * (k + 0)];
        tmp_3_0 = _mm512_fmadd_pd( tmpa_0, tmpb_3, tmp_3_0 );
        tmp_3_1 = _mm512_fmadd_pd( tmpa_1, tmpb_3, tmp_3_1 );
        tmp_3_2 = _mm512_fmadd_pd( tmpa_2, tmpb_3, tmp_3_2 );
        tmp_3_3 = _mm512_fmadd_pd( tmpa_3, tmpb_3, tmp_3_3 );
        tmpb_0 = b[i + 0 + (32) * (k + 1)];
        tmpa_0 = _mm512_set1_pd( a[k + 1 + (256) * (j + 0)] );
        tmp_0_0 = _mm512_fmadd_pd( tmpa_0, tmpb_0, tmp_0_0 );
        tmpa_1 = _mm512_set1_pd( a[k + 1 + (256) * (j + 1)] );
        tmp_0_1 = _mm512_fmadd_pd( tmpa_1, tmpb_0, tmp_0_1 );
        tmpa_2 = _mm512_set1_pd( a[k + 1 + (256) * (j + 2)] );
        tmp_0_2 = _mm512_fmadd_pd( tmpa_2, tmpb_0, tmp_0_2 );
        tmpa_3 = _mm512_set1_pd( a[k + 1 + (256) * (j + 3)] );
        tmp_0_3 = _mm512_fmadd_pd( tmpa_3, tmpb_0, tmp_0_3 );
        tmpb_1 = b[i + 1 + (32) * (k + 1)];
        tmp_1_0 = _mm512_fmadd_pd( tmpa_0, tmpb_1, tmp_1_0 );
        tmp_1_1 = _mm512_fmadd_pd( tmpa_1, tmpb_1, tmp_1_1 );
        tmp_1_2 = _mm512_fmadd_pd( tmpa_2, tmpb_1, tmp_1_2 );
        tmp_1_3 = _mm512_fmadd_pd( tmpa_3, tmpb_1, tmp_1_3 );
        tmpb_2 = b[i + 2 + (32) * (k + 1)];
        tmp_2_0 = _mm512_fmadd_pd( tmpa_0, tmpb_2, tmp_2_0 );
        tmp_2_1 = _mm512_fmadd_pd( tmpa_1, tmpb_2, tmp_2_1 );
        tmp_2_2 = _mm512_fmadd_pd( tmpa_2, tmpb_2, tmp_2_2 );
        tmp_2_3 = _mm512_fmadd_pd( tmpa_3, tmpb_2, tmp_2_3 );
        tmpb_3 = b[i + 3 + (32) * (k + 1)];
        tmp_3_0 = _mm512_fmadd_pd( tmpa_0, tmpb_3, tmp_3_0 );
        tmp_3_1 = _mm512_fmadd_pd( tmpa_1, tmpb_3, tmp_3_1 );
        tmp_3_2 = _mm512_fmadd_pd( tmpa_2, tmpb_3, tmp_3_2 );
        tmp_3_3 = _mm512_fmadd_pd( tmpa_3, tmpb_3, tmp_3_3 );
      }
      c[i + 0 + (32) * (j + 0)] = tmp_0_0;
      c[i + 1 + (32) * (j + 0)] = tmp_1_0;
      c[i + 2 + (32) * (j + 0)] = tmp_2_0;
      c[i + 3 + (32) * (j + 0)] = tmp_3_0;
      c[i + 0 + (32) * (j + 1)] = tmp_0_1;
      c[i + 1 + (32) * (j + 1)] = tmp_1_1;
      c[i + 2 + (32) * (j + 1)] = tmp_2_1;
      c[i + 3 + (32) * (j + 1)] = tmp_3_1;
      c[i + 0 + (32) * (j + 2)] = tmp_0_2;
      c[i + 1 + (32) * (j + 2)] = tmp_1_2;
      c[i + 2 + (32) * (j + 2)] = tmp_2_2;
      c[i + 3 + (32) * (j + 2)] = tmp_3_2;
      c[i + 0 + (32) * (j + 3)] = tmp_0_3;
      c[i + 1 + (32) * (j + 3)] = tmp_1_3;
      c[i + 2 + (32) * (j + 3)] = tmp_2_3;
      c[i + 3 + (32) * (j + 3)] = tmp_3_3;
    }
  }
}
void gemm_256_256_256(const double * __restrict__ a, const __m512d * __restrict__ b, __m512d * __restrict__ c){
  __assume_aligned(a, 64);
  gemm_inn_64_48_128( &a[0 + (256) * (0)],  &b[0 + (32) * (0)],  &c[0 + (32) * (0)]);
  gemm_inn_64_48_128( &a[0 + (256) * (0)],  &b[8 + (32) * (0)],  &c[8 + (32) * (0)]);
  gemm_inn_64_48_128( &a[0 + (256) * (0)],  &b[16 + (32) * (0)],  &c[16 + (32) * (0)]);
  gemm_inn_64_48_128( &a[0 + (256) * (0)],  &b[24 + (32) * (0)],  &c[24 + (32) * (0)]);
  gemm_inn_64_48_128( &a[0 + (256) * (48)],  &b[0 + (32) * (0)],  &c[0 + (32) * (48)]);
  gemm_inn_64_48_128( &a[0 + (256) * (48)],  &b[8 + (32) * (0)],  &c[8 + (32) * (48)]);
  gemm_inn_64_48_128( &a[0 + (256) * (48)],  &b[16 + (32) * (0)],  &c[16 + (32) * (48)]);
  gemm_inn_64_48_128( &a[0 + (256) * (48)],  &b[24 + (32) * (0)],  &c[24 + (32) * (48)]);
  gemm_inn_64_48_128( &a[0 + (256) * (96)],  &b[0 + (32) * (0)],  &c[0 + (32) * (96)]);
  gemm_inn_64_48_128( &a[0 + (256) * (96)],  &b[8 + (32) * (0)],  &c[8 + (32) * (96)]);
  gemm_inn_64_48_128( &a[0 + (256) * (96)],  &b[16 + (32) * (0)],  &c[16 + (32) * (96)]);
  gemm_inn_64_48_128( &a[0 + (256) * (96)],  &b[24 + (32) * (0)],  &c[24 + (32) * (96)]);
  gemm_inn_64_48_128( &a[0 + (256) * (144)],  &b[0 + (32) * (0)],  &c[0 + (32) * (144)]);
  gemm_inn_64_48_128( &a[0 + (256) * (144)],  &b[8 + (32) * (0)],  &c[8 + (32) * (144)]);
  gemm_inn_64_48_128( &a[0 + (256) * (144)],  &b[16 + (32) * (0)],  &c[16 + (32) * (144)]);
  gemm_inn_64_48_128( &a[0 + (256) * (144)],  &b[24 + (32) * (0)],  &c[24 + (32) * (144)]);
  gemm_inn_64_48_128( &a[0 + (256) * (192)],  &b[0 + (32) * (0)],  &c[0 + (32) * (192)]);
  gemm_inn_64_48_128( &a[0 + (256) * (192)],  &b[8 + (32) * (0)],  &c[8 + (32) * (192)]);
  gemm_inn_64_48_128( &a[0 + (256) * (192)],  &b[16 + (32) * (0)],  &c[16 + (32) * (192)]);
  gemm_inn_64_48_128( &a[0 + (256) * (192)],  &b[24 + (32) * (0)],  &c[24 + (32) * (192)]);
  gemm_inn_64_16_128( &a[0 + (256) * (240)],  &b[0 + (32) * (0)],  &c[0 + (32) * (240)]);
  gemm_inn_64_16_128( &a[0 + (256) * (240)],  &b[8 + (32) * (0)],  &c[8 + (32) * (240)]);
  gemm_inn_64_16_128( &a[0 + (256) * (240)],  &b[16 + (32) * (0)],  &c[16 + (32) * (240)]);
  gemm_inn_64_16_128( &a[0 + (256) * (240)],  &b[24 + (32) * (0)],  &c[24 + (32) * (240)]);
  gemm_inn_64_48_128( &a[128 + (256) * (0)],  &b[0 + (32) * (128)],  &c[0 + (32) * (0)]);
  gemm_inn_64_48_128( &a[128 + (256) * (0)],  &b[8 + (32) * (128)],  &c[8 + (32) * (0)]);
  gemm_inn_64_48_128( &a[128 + (256) * (0)],  &b[16 + (32) * (128)],  &c[16 + (32) * (0)]);
  gemm_inn_64_48_128( &a[128 + (256) * (0)],  &b[24 + (32) * (128)],  &c[24 + (32) * (0)]);
  gemm_inn_64_48_128( &a[128 + (256) * (48)],  &b[0 + (32) * (128)],  &c[0 + (32) * (48)]);
  gemm_inn_64_48_128( &a[128 + (256) * (48)],  &b[8 + (32) * (128)],  &c[8 + (32) * (48)]);
  gemm_inn_64_48_128( &a[128 + (256) * (48)],  &b[16 + (32) * (128)],  &c[16 + (32) * (48)]);
  gemm_inn_64_48_128( &a[128 + (256) * (48)],  &b[24 + (32) * (128)],  &c[24 + (32) * (48)]);
  gemm_inn_64_48_128( &a[128 + (256) * (96)],  &b[0 + (32) * (128)],  &c[0 + (32) * (96)]);
  gemm_inn_64_48_128( &a[128 + (256) * (96)],  &b[8 + (32) * (128)],  &c[8 + (32) * (96)]);
  gemm_inn_64_48_128( &a[128 + (256) * (96)],  &b[16 + (32) * (128)],  &c[16 + (32) * (96)]);
  gemm_inn_64_48_128( &a[128 + (256) * (96)],  &b[24 + (32) * (128)],  &c[24 + (32) * (96)]);
  gemm_inn_64_48_128( &a[128 + (256) * (144)],  &b[0 + (32) * (128)],  &c[0 + (32) * (144)]);
  gemm_inn_64_48_128( &a[128 + (256) * (144)],  &b[8 + (32) * (128)],  &c[8 + (32) * (144)]);
  gemm_inn_64_48_128( &a[128 + (256) * (144)],  &b[16 + (32) * (128)],  &c[16 + (32) * (144)]);
  gemm_inn_64_48_128( &a[128 + (256) * (144)],  &b[24 + (32) * (128)],  &c[24 + (32) * (144)]);
  gemm_inn_64_48_128( &a[128 + (256) * (192)],  &b[0 + (32) * (128)],  &c[0 + (32) * (192)]);
  gemm_inn_64_48_128( &a[128 + (256) * (192)],  &b[8 + (32) * (128)],  &c[8 + (32) * (192)]);
  gemm_inn_64_48_128( &a[128 + (256) * (192)],  &b[16 + (32) * (128)],  &c[16 + (32) * (192)]);
  gemm_inn_64_48_128( &a[128 + (256) * (192)],  &b[24 + (32) * (128)],  &c[24 + (32) * (192)]);
  gemm_inn_64_16_128( &a[128 + (256) * (240)],  &b[0 + (32) * (128)],  &c[0 + (32) * (240)]);
  gemm_inn_64_16_128( &a[128 + (256) * (240)],  &b[8 + (32) * (128)],  &c[8 + (32) * (240)]);
  gemm_inn_64_16_128( &a[128 + (256) * (240)],  &b[16 + (32) * (128)],  &c[16 + (32) * (240)]);
  gemm_inn_64_16_128( &a[128 + (256) * (240)],  &b[24 + (32) * (128)],  &c[24 + (32) * (240)]);
}
